{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchinfo import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SummaryWriter instance\n",
    "writer = SummaryWriter(f\"runs/autoencoder/{datetime.datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path: ae.ipynb\n",
    "def create_dl_links():\n",
    "    dl_list =[]\n",
    "    files = os.listdir(\"combined\")\n",
    "    for i in range(len(files)):\n",
    "        with open(\"combined/\" + files[i], \"r\") as file:\n",
    "            data = json.load(file)\n",
    "            for j in range(len(data)):\n",
    "                date = data[j][\"date\"].split(\" \")\n",
    "                date.remove(date[-1])\n",
    "                date = date[0].replace(\"-\", \"/\")\n",
    "                img = data[j][\"image\"] + \".png\"\n",
    "                link = f\"https://epic.gsfc.nasa.gov/archive/enhanced/{date}/png/{img}\"\n",
    "                dl_list.append(link)\n",
    "    return dl_list\n",
    "\n",
    "list = create_dl_links()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device (Acceleration if available, else CPU)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Set manual seed for reproducibility\n",
    "torch.manual_seed(2001110219971207)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the autoencoder architecture\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            ## nn.Identity(), # Does nothing\n",
    "            nn.Conv2d(in_channels=3, out_channels=3, kernel_size=8,  stride=2, padding=3), # Could be: Padding = (kernel_size - 1) / 2 to retain input size\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=3, out_channels=3, kernel_size=8, stride=2, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=3, out_channels=3, kernel_size=8, stride=2, padding=3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            ## nn.Identity(), # Does nothing\n",
    "            # now trying to reverse the encoder\n",
    "            nn.ConvTranspose2d(in_channels=3, out_channels=3, kernel_size=8, stride=2, padding=3),\n",
    "            nn.ConvTranspose2d(in_channels=3, out_channels=3, kernel_size=8, stride=2, padding=3),\n",
    "            nn.ConvTranspose2d(in_channels=3, out_channels=3, kernel_size=8, stride=2, padding=3),          \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Analysis of the model\n",
    "print(summary(Autoencoder(), input_size=(1, 3, 512, 512))) # Static\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyperparameters\n",
    "batch_size = 8\n",
    "learning_rate = 0.001\n",
    "num_epochs = 30\n",
    "use_batch_download = False # Download random images\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Initialize the autoencoder and loss function\n",
    "autoencoder = Autoencoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "# Visualize the model in TensorBoard \n",
    "writer.add_graph(autoencoder, torch.rand(1, 3, 512, 512).to(device)) # Static\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    if use_batch_download:\n",
    "    # Download data and preprocess\n",
    "        for i in range(batch_size):\n",
    "            # Download data\n",
    "            # Pick random image from list\n",
    "            rand = random.randint(0, len(list))\n",
    "            os.system(f\"wget -P download/earth {list[rand]} --quiet\")\n",
    "        \n",
    "    # Load data\n",
    "    dataset = ImageFolder(root='download', transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "    for data in dataloader:\n",
    "        img, _ = data\n",
    "        img = img.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output = autoencoder(img)\n",
    "        loss = criterion(output, img)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Prepare the last reconstructed image \n",
    "    img_out = output\n",
    "    img_out = img_out.detach().cpu()\n",
    "    img_out.detach().numpy()\n",
    "\n",
    "    # Log losses\n",
    "    writer.add_scalar(\"Loss\", loss.item(), epoch, time.time())\n",
    "\n",
    "    # Log input and output images\n",
    "    writer.add_image(\"Input\", make_grid(img), epoch)\n",
    "    writer.add_image(\"Output\", make_grid(img_out), epoch)\n",
    "\n",
    "    # Project image to tensorboard, idk what this does   \n",
    "    writer.add_embedding(output[0][0], global_step=epoch, tag=\"Output\")\n",
    "\n",
    "    # Clear download folder\n",
    "    if use_batch_download:\n",
    "        os.system(\"rm download/earth/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(autoencoder.state_dict(), 'autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained model\n",
    "model = Autoencoder()\n",
    "model.load_state_dict(torch.load('autoencoder.pth'))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
