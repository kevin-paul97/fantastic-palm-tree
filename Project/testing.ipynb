{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import webbrowser\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from rich.progress import track\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder, DatasetFolder\n",
    "from torch.utils.data import Dataset\n",
    "from torchinfo import summary\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.PILToTensor()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(root=\"pics_with_coords\", transform=transforms)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinNet, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(512, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(train_dataloader)\n",
    "data = next(data_iter)\n",
    "\n",
    "x, _ = data\n",
    "x = x.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1996"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "filenames = [train_dataloader.dataset.imgs[i][0].split('/')[-1] for i in range(len(train_dataset))]\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epic_RGB_20150803015633_9.089355_159.250488.png\n",
      "[[9.089355]] [[159.250488]]\n",
      "[[0.10099283]] [[0.88472493]]\n",
      "[[9.089355]] [[159.250488]]\n"
     ]
    }
   ],
   "source": [
    "lat_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "lon_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "img_num = 1 \n",
    "\n",
    "lat = train_dataloader.dataset.imgs[img_num][0].strip(\".png\").split(\"_\")[-2]\n",
    "lon = train_dataloader.dataset.imgs[img_num][0].strip(\".png\").split(\"_\")[-1]\n",
    "\n",
    "filename = train_dataloader.dataset.imgs[img_num][0].split('/')[-1]\n",
    "\n",
    "lat_scaler.fit(np.array([[-90], [90]]))\n",
    "lon_scaler.fit(np.array([[-180], [180]]))\n",
    "\n",
    "lat = np.array([[float(lat)]])\n",
    "lon = np.array([[float(lon)]])\n",
    "scaled_lat = lat_scaler.transform(lat)\n",
    "scaled_lon = lon_scaler.transform(lon)\n",
    "inv_scaled_lat = lat_scaler.inverse_transform(scaled_lat)\n",
    "inv_scaled_lon = lon_scaler.inverse_transform(scaled_lon)\n",
    "\n",
    "print(filename)\n",
    "print(lat, lon)\n",
    "print(scaled_lat, scaled_lon)\n",
    "print(inv_scaled_lat, inv_scaled_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.09668]] [[0.10107422]]\n",
      "[[-173.71582]] [[-0.96508789]]\n",
      "tensor([[-0.9651],\n",
      "        [-0.9651]])\n",
      "epic_RGB_20150803000829_9.09668_-173.71582.png\n"
     ]
    }
   ],
   "source": [
    "for num, image in enumerate(filenames):\n",
    "    '''\n",
    "    1. Extract lat and lon\n",
    "    2. Scale lat and lon to (-1, 1)\n",
    "    3. Make Tensor for criterion\n",
    "    '''\n",
    "    lat = train_dataloader.dataset.imgs[num][0].strip(\".png\").split(\"_\")[-2]\n",
    "    lon = train_dataloader.dataset.imgs[num][0].strip(\".png\").split(\"_\")[-1]\n",
    "    lat = np.array([[float(lat)]])\n",
    "    lon = np.array([[float(lon)]])\n",
    "    scaled_lat = lat_scaler.transform(lat)\n",
    "    scaled_lon = lon_scaler.transform(lon)\n",
    "\n",
    "    print(lat, scaled_lat)\n",
    "    print(lon, scaled_lon)\n",
    "\n",
    "    target = torch.Tensor([scaled_lon[0], scaled_lon[0]])\n",
    "    print(target)\n",
    "\n",
    "    print(image)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
